\section{Related work}\label{sect.relatedwork}

In a system where different nodes may concurrently perform updates without coordinating with each other, strong eventual consistency requires a conflict resolution algorithm to reconcile concurrent updates. 
In some cases, a trivial algorithm is used, for example:
\begin{description}
\item[User-defined conflict resolution:] Some systems store all conflicting versions of the data,
and either leave it for manual resolution by a user, or invoke a user-defined merge function.
However, manual resolution is an unacceptable burden for the user in many applications, and defining
merge functions in application code is error-prone; for example, \citet{DeCandia:2007ui} describe a
shopping cart anomaly at Amazon that arose due to poor conflict resolution.

\item[Last write wins (LWW):] Each version of the data structure is assigned a unique timestamp.
When there is a conflict, the system picks the version with the highest timestamp and discards other
versions. Apache Cassandra takes this approach, for example \cite{KingsburyCassandra}.
Although LWW achieves convergence, it does so at the cost of losing user input, which is often unacceptable.
\end{description}
However, there are also algorithms that achieve convergence automatically, without discarding updates.
In Section~\ref{sect.related.ot.crdts} we summarise two main lines of work, CRDTs and OT, which have the same fundamental goal of conflict resolution and convergence, but which take different approaches towards achieving it.
In Section~\ref{sect.related.verification} we discuss existing work on formal verification of those algorithms.

\subsection{Operational Transformation (OT) and Conflict-free Replicated Data Types (CRDTs)}\label{sect.related.ot.crdts}

Algorithms for achieving strong eventual consistency have been studied extensively in the context of collaborative editing and groupware.
The \emph{operational transformation} (OT) approach was developed to allow several users to concurrently modify a document, applying edits immediately to their local copy, propagating them asynchronously to other users, and automatically resolving any conflicts such that all nodes converge towards the same state.

OT algorithms for text documents include dOPT \cite{Ellis:1989ue}, Jupiter \cite{Nichols:1995fd}, adOPTed \cite{Ressel:1996wx}, GOT \cite{Sun:1998un}, GOTO \cite{Sun:1998vf}, SOCT2 \cite{Suleiman:1997gl,Suleiman:1998eu}, SOCT3/4 \cite{Vidot:2000ch}, IMOR \cite{Imine:2003ks}, SDT \cite{Li:2004er,Li:2008hw}, and TTF \cite{Oster:2006tr}.
The approach has also been generalised to other data structures such as XML trees \cite{Ignat:2003jy,Davis:2002iv,Jungnickel:2015ua} and vector graphics documents \cite{Sun:2002jb}.

Many OT algorithms assume that operations are sequenced through a central server and delivered to all clients in the same order.
This design was originally pioneered by the Jupiter system \cite{Nichols:1995fd} and is now used by all widely-deployed OT-based collaboration systems, including Google Docs \cite{DayRichter:2010tt}, Microsoft Word Online, Etherpad \cite{Etherpad:2011um}, Google Wave/Apache Wave \cite{Wang:2015vo}, and Novell Vibe \cite{Spiewak:2010vw}.

OT algorithms track the version of the document in which each operation applies, and if an operation needs to be applied to a later document version (because another, concurrent operation has already been applied), the operation must be transformed.
\citet{Ressel:1996wx} introduced two properties that the OT transformation function must satisfy, which are known as $\mathit{TP}_1$ and $\mathit{TP}_2$.

Given two concurrent operations $x$ and $y$ that modify the same initial state, $\mathit{TP}_1$ requires that $y$ can be transformed into an operation $y'$ that performs an equivalent modification on a state where $x$ has already been applied, and vice versa, such that $x \circ y' = y \circ x'$.
Systems that sequence operations through a central server need only satisfy $\mathit{TP}_1$ because each client only needs to reorder its operations with respect to the server's operation sequence.

However, as discussed in the introduction, we are interested in replication algorithms for decentralised systems without any central server.
If there are three concurrent operations $x$, $y$, and $z$ that modify the same initial state, and those operations can be applied in any order, $\mathit{TP}_1$ does not suffice, and the $\mathit{TP}_2$ property must also be satisfied.
$\mathit{TP}_2$ requires that if transformations of $x$ and $y$ are applied in either order, the same transformation of $z$ can be applied to the result: $x \circ y' \circ z' = y \circ x' \circ z'$.
Since transformed operations may be different from original operations, this property demands much more than just commutativity, making it difficult to implement correctly.
We show in Section~\ref{sect.related.verification} how almost all OT algorithms have failed to satisfy $\mathit{TP}_2$.

Instead, \emph{conflict-free replicated data types} (CRDTs) have been developed to achieve SEC in decentralised systems.
As we have noted, CRDTs make operations commutative by design by attaching additional metadata to the data structure.
To propagate changes between nodes, a CRDT either captures every update as an operation and broadcasts it to other nodes (an \emph{operation-based} CRDT), or periodically broadcasts its entire node state (a \emph{state-based} CRDT).
Operation-based CRDTs require operations to commute; state-based CRDTs require a merge function over a join-semilattice, allowing two states to be combined such that the result reflects changes made in both nodes \cite{Shapiro:2011wy,Shapiro:2011un}.
State-based CRDTs have been deployed commercially in the Riak database \cite{Brown:2014hs}, but in this work we focus on operation-based algorithms, because all known CRDTs for text editing and ordered lists are operation-based.

As with OT, several CRDTs for text documents have been developed, including RGA \cite{Roh:2011dw}, Treedoc \cite{Preguica:2009fz}, WOOT \cite{Oster:2006wj}, Logoot \cite{Weiss:2010hx}, and LSEQ \cite{Nedelec:2013ky,Nedelec:2016eo}.
Other datatypes include registers and counters \cite{Shapiro:2011wy,Shapiro:2011un}, maps \cite{Baquero:2016iv}, sets \cite{Bieniusa:2012wu,Bieniusa:2012gt}, XML \cite{Martin:2010ih}, and JSON trees \cite{Kleppmann:2016ve}.
Cloud types \cite{Burckhardt:2012jy} have similarities to CRDTs, using a relational data model.


\subsection{Formal verification}\label{sect.related.verification}

The history of algorithms for achieving convergence in a distributed setting has been fraught with difficulty.
Informal reasoning has repeatedly produced approaches that fail to converge in certain scenarios, and even several formal ``proofs'' later turned out to be false, as explained below.
For OT, as described in Section~\ref{sect.related.ot.crdts}, convergence in this setting requires satisfying the $\mathit{TP}_1$ and $\mathit{TP}_2$ properties.
While $\mathit{TP}_1$ has proved to be readily achievable in practice, and all the aforementioned widely-deployed OT systems rely on it, the $\mathit{TP}_2$ property has been a significant source of problems.

The original peer-reviewed publications of dOPT, adOPTed, IMOR, SOCT2, and SDT all claimed that their transformation functions satisfied $\mathit{TP}_2$, but those claims were subsequently shown to be false by giving counter-examples \cite{Imine:2003ks,Imine:2006kn,Oster:2005vi}.
In the case of dOPT and adOPTed, the $\mathit{TP}_2$ claim had originally been asserted without proof.
In the case of SOCT2 and SDT, there were hand-written ``proofs'' that later turned out to be incorrect.
For IMOR and SOCT2, there had even been machine-checked ``proofs'' \cite{Imine:2003ks}, but \citet{Oster:2005vi} showed that they were also invalid because they had made incorrect assumptions.

\citet{Randolph:2015gj} have even shown that in the classic formulation of OT it is impossible to
achieve $\mathit{TP}_2$. To our knowledge, TTF is at present the only $\mathit{TP}_2$-claiming OT
algorithm for which no counter-example is known, and it circumvents the impossibility result of
\citet{Randolph:2015gj} by using a different formulation of the transformation
\cite{Oster:2006tr,Levien:2016wz}.

Formal proofs of the $\mathit{TP}_1$ property have been more successful: \citet{Sinchuk:2016cf} use Coq to verify that their algorithm satisfies $\mathit{TP}_1$, and \citet{Jungnickel:2015ua} use Isabelle/HOL for the same purpose.
For CRDTs, the only machine-checked verification of which we are aware is an Isabelle formalisation of state-based sets, registers, and counters by \citet{Zeller:2014fl}; this work does not consider any list datatypes or any operation-based CRDTs.

The convergence of the RGA CRDT for ordered lists, which we study in this paper, has previously been
demonstrated in handwritten proofs \cite{Attiya:2016kh,Kleppmann:2016ve,Roh:2009ws}. Although we
have no reason to doubt the correctness of those proofs, the historic experience with
$\mathit{TP}_2$ makes us wary of claims whose assumptions and reasoning process have not been
checked rigorously. Other authors have also pointed out that handwritten proofs are laborious and
difficult to check by hand \cite{Li:2008hw,Li:2005jq}.

To our knowledge, our work is the first mechanised proof of operation-based CRDTs in general, and of
any ordered list CRDT in particular. As \citet{Oster:2005vi} have demonstrated, machine-checked
proofs are not immune to errors that are due to false assumptions. To avoid this trap, we prove not
only the commutativity of operations (which is subject to certain assumptions), but also that those
assumptions are guaranteed to hold in all behaviours of our network model. The network model in turn
is specified by a small set of axioms that are not specific to any particular CRDT, and whose
correctness can be robustly defended (see Section~\ref{sect.network}).

\citet{Burckhardt:2014ft} present a framework for specifying and reasoning about replicated datatypes, but do not support mechanised proofs at present, and use different techniques to those described in this paper.

More generally, applying verification techniques to distributed systems is an active area of research.
Interactive theorem provers~\cite{DBLP:conf/pldi/WilcoxWPTWEA15,DBLP:journals/afp/DebratM12,DBLP:conf/sss/Charron-BostDM11}, model checkers~\cite{DBLP:conf/asm/AzmyMW16,DBLP:journals/entcs/JohnsonLLV04}, and formal specification tools~\cite{DBLP:journals/ijaacs/TounsiMM16,DBLP:conf/asm/AndriamiarinaMS14,DBLP:conf/wetice/TounsiMM13} have all been adopted for the verification and specification of distributed systems, algorithms, and protocols.
Interestingly, recent empirical work~\cite{DBLP:conf/eurosys/FonsecaZWK17} has found that several verified distributed systems contain critical bugs that can cause runtime crashes or the return of incorrect results to clients---violating the supposed guarantees offered by their correctness theorems.
A common cause of these bugs is a mismatch between the assumptions made when verifying the system and the guarantees offered by the underlying network, libraries, and operating system infrastructure upon which they are built.
We see this as compelling evidence that verifying distributed systems starting from a model of the network and building up, as we do in this work, is a robust approach to distributed systems verification.
