\documentclass[acmlarge,review,anonymous]{acmart}\settopmatter{printfolios=true}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}
\usepackage[english]{babel}
\usepackage{setspace}

\usepackage{paralist} % For inline enumeration
\usepackage{tikz} % For diagrams
\usetikzlibrary{arrows}

\usepackage{isabelle,isabellesym}
\isabellestyle{it}

\hyphenation{App-Jet}

\setcopyright{none} % For review submission

\begin{document}
\title{Verifying Strong Eventual Consistency in Distributed Systems}
%\author{Victor~B.~F.~Gomes, Martin Kleppmann, Dominic P.~Mulligan,\\Alastair R. Beresford}
%\date{Computer Laboratory, University of Cambridge}

\begin{abstract}
Data replication is commonly used in distributed systems to maintain an up-to-date copy of a data structure across multiple computers. There are a wide variety of data replication algorithms which explore the trade-off between varying levels of data consistency across computers versus operational constraints and system performance. This paper focuses on a class of algorithms which provide Strong Eventual Consistency (SEC), including Operational Transformations (OTs) and Conflict-free Replicated Data Types (CRDTs). These algorithms are worthy of study not only because they are widely used today, but also because previous peer-reviewed SEC algorithms have later turned out to be incorrect, including those which claim to provide a mechanised proof of correctness. Such past failures occurred because the axioms used in proofs were subsequently shown to contained subtle errors. The core difficulty in designing SEC algorithms arises from the fact that computer networks may delay, drop and reorder messages sent between computers. We therefore build on this foundation and start by constructing a realistic, formal model of how a computer network enables communication between machines in a distributed system using just five simple axioms. We implement our framework using Isabelle, an interactive theorem prover, and use it to prove the correctness of SEC algorithms across all possible combinations of message delays, re-orderings and deletions. In particular, we provide the first mechanised proofs of counter, set and ordered-list CRDTs. We also demonstrate our framework is highly reusable -- our second and third proofs took a few hours of time and under 100 lines of additional code.
\end{abstract}
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sect.introduction}

It is almost a clich{\' e} to say that programming distributed systems is hard. Even the most basic
needs of applications---such as \emph{replication}, that is, maintaining a consistent copy of some
data on several nodes---turn out to be difficult to reliably achieve in the face of unreliable
networks and node failures. In this context, a node can be any computer connected to a network, such
as a server in a datacenter, a laptop, a smartphone, or a self-driving car.

Two instances of the replication problem are
\begin{inparaenum}
\item \emph{collaborative editing}, where the data in question is typically a document (text,
    spreadsheet, graphics, CAD, etc.), and several users need to work on it;
\item \emph{data synchronisation}---for example of calendars, address books, note-taking tools,
    to-do lists, and password managers---which is used when a user owns several devices and wants
    the data accessible on each device.
\end{inparaenum}
In both instances, the system must either enforce an exclusive lock for one node and prevent others
from modifying the data concurrently, or deal with the conflicts that ensue when edits are made
concurrently on different nodes.

Enforcing an exclusive lock implies making the data unavailable for writes when a node is offline,
i.e., when it cannot check whether another node already has the lock. Such unavailability is not
acceptable in many applications, so the latter route of accepting and handling conflicts is widely
used: most calendar, address book, and note-taking apps on smartphones, and popular collaborative
editing applications such as Google Docs/Sheets and Microsoft Office Online, choose to allow
conflicts and have mechanisms for resolving them.

However, despite decades of work in both industry and academia, algorithms for achieving replication
with conflict resolution in distributed systems are still poorly understood. As we document in
Section~\ref{sect.relatedwork}, many published algorithms have been shown to be broken, corrupting
the data they are supposed to replicate. Those that are correct tend to be very subtle and easy to
get wrong.

In this work we advance the state of the art of distributed programming by establishing a framework
for formally verifying the correctness of algorithms for achieving consistency in replication,
conflict resolution, and data synchronisation. We demonstrate, for the first time, machine-checked
proofs of correctness of several replicated data structures. Our framework provides general-purpose
tools for such correctness proofs, allowing other algorithms to be verified more easily in future.

%%%%%

Most deployed systems today address replication problems by relying on a central server that is
trusted to hold the authoritative copy of the data, i.e. by making the distributed system less
distributed. The use of a central server introduces a number of limitations:
\begin{itemize}
\item It limits offline usage: for example, a user cannot synchronise changes between their
    smartphone and laptop via a local wireless connection, but must instead connect both devices to
    the internet. It also rules out a group of users collaborating on a local network disconnected
    from the server, for example in a remote location without reliable internet connectivity.
\item Since the central server holds the authoritative copy of the data, all participants must be
    willing to trust it to a high degree. If the server were compromised by attackers, or subverted
    by a malicious insider, it could tamper with the data or grant access to unauthorised parties.
\item Finally, a central server is a single point of failure that is susceptible to distributed
    denial-of-service (DDoS) attacks, blocking, and censorship. For important services that require
    high availability, the risk of being knocked offline by a DDoS attack might be unacceptable. In
    sensitive situations, such as communication among journalists and dissidents under a repressive
    regime, centralisation of communication is also problematic.
\end{itemize}

Decentralised peer-to-peer systems therefore look attractive in scenarios where reliance on a
central server is impractical or undesirable. Unfortunately, we currently have a poor understanding
of algorithms that enable collaborative editing and data synchronisation in peer-to-peer networks.
In Section~\ref{sect.relatedwork} we highlight several algorithms for peer-to-peer collaboration,
published in peer-reviewed venues, that claimed to work correctly but were subsequently shown to violate
their supposed guarantees. Informal reasoning in this domain has repeatedly produced algorithms that
look plausible, but actually turn out to be flawed.

In this work, we contribute to a better understanding of algorithms for peer-to-peer collaboration
by establishing techniques for formally verifying their correctness. We use Isabelle, a generic
proof assistant tool \cite{DBLP:conf/tphol/WenzelPN08}, to create formal specifications of an
asynchronous network and distributed algorithms executing in such a system. We then use this
framework to produce a machine-checked proof of correctness of one particular algorithm for
peer-to-peer collaboration---the Replicated Growable Array (RGA) of \citet{Roh:2011dw}, an example
of a Conflict-Free Replicated Data Type (CRDT) as introduced by
\citet{Shapiro:2011wy,Shapiro:2011un}.
The algorithm is subtle---\citet{Attiya:2016kh} wrote, ``the reason why RGA actually works has been
a bit of a mystery''---which makes formal verification particularly important.

% TODO say more about our contributions. Can recycle some of the following text, but probably needs
% adapting, as the explanation of CRDTs and OT has been moved to the background section...
%
% To date there has been little formal verification of the correctness of CRDTs, and the
% history of broken OT algorithms highlights the inadequacy of informal reasoning in this domain. In
% this work we contribute to the formal basis of collaborative editing algorithms by using the
% interactive proof assistant Isabelle to develop machine-checked proofs of the
% correctness for CRDTs.
%
% By including a model of the network in our proof, we rule out a larger set of potential errors in
% the algorithm that may result from the interaction of operation properties with assumptions about
% the network. Moreover, our network model and convergence theorems are independent of any particular
% CRDT, so they can be reused for correctness proofs of any other replicated datatype that is based on
% operation commutativity, encompassing a wide range of CRDTs~\cite{Baquero:2014ed}.
%
% Besides presenting the first machine-checked proof of the RGA algorithm, our main contribution in
% this paper is to establish a modular toolkit of proof techniques and building blocks for
% machine-checked correctness proofs of operation-based CRDTs. Our proofs are broken down into modules
% with well-defined properties, allowing modules to be reused for proofs of new datatypes in future.
% By making formal verification easier, we hope to provide a strong foundation for the development of

% the next generation of algorithms for collaborative editing.

% TODO put this in section on high-level proof strategy, and just have a forward reference here?
%Our proof is structured in four modules:
%\begin{inparaenum}
%    \item a general convergence theorem that applies in any system where concurrent operations are
%        commutative;
%    \item a formal model of a network protocol providing reliable, causally-ordered broadcast;
%    \item an implementation of the RGA algorithm, and a proof that well-formed, concurrent insertion
%        and deletion operations commute; and
%    \item a proof that when the RGA algorithm is executed in our network model, all possible
%        executions are well-formed, and thus converge.
%\end{inparaenum}


\input{background}
\input{relwork}
\input{isabelle}
\input{convergence}
\input{network}
\input{rga}
\input{simple-crdts}

\section{Discussion}
\label{sect.discussion}

All of our convergence proofs for our CRDT implementations follow a familiar recipe.
First the type of local states, corresponding to the concrete implementation of the replicated type, is defined along with a type of messages corresponding to the operations supported by the CRDT.
Together, these are coupled with an interpretation function which `decodes' messages and lifts them into a transformer of local states.
This transformer is used to define a CRDT-specific locale, a specialisation of the $\isa{network}{\isacharunderscore}\isa{with}{\isacharunderscore}\isa{ops}$ locale, which may also provide restrictions on valid network behaviours in order to ensure convergence.
Next, all operations are shown to commute with themselves, and with each other, with preconditions on commutation being eventually dischargeable as a side-effect of the restrictions on network behaviours mentioned above.
Coupling our abstract convergence theorem with a CRDT-specific technical lemma showing that the concurrent delivered messages of a prefix of a local history of a node commute, it is easy to prove convergence.
In fact, the same single line of Isabelle proof is used to obtain the convergence theorem as a corollary, in all of our three concrete CRDT implementations.

As this recipe described above demonstrates, in this work we have not only isolated a series of reusable lemmas and models of networks, but also identified a fixed proof strategy that developers of new operation-based CRDTs can use to obtain a convergence theorem for their replicated type.

\subsection{Limitations}
\label{sect.limitations}

\section{Conclusion}
\label{sect.conclusion}

\section*{Acknowledgements}

\bibliography{references}{}

\input{appendix}

\end{document}
