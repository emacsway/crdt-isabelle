\documentclass[acmlarge,review,anonymous]{acmart}

\settopmatter{printfolios=true}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}

\usepackage[english]{babel}
\usepackage{setspace}

\usepackage{paralist}
\usepackage{tikz}
\usetikzlibrary{arrows}

\usepackage{isabelle,isabellesym}
\isabellestyle{it}

\hyphenation{App-Jet}

%% PACMPL journal information will be supplied by publisher for camera-ready submission
\acmJournal{PACMPL}
\acmVolume{--}
\acmNumber{--}
\acmArticle{0}
\acmYear{2017}
\acmMonth{4}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}

\widowpenalty=2000
\clubpenalty=2000

\begin{document}
\title{Verifying Strong Eventual Consistency in Distributed Systems}

%% Each author should be introduced by \author, followed by \authornote (optional),
%% \orcid (optional), \affiliation, and \email.
%% An author may have multiple affiliations and/or emails; repeat the appropriate command.
%% Many elements are not rendered, but should be provided for metadata extraction tools.
\author{Victor B.\ F.\ Gomes}
\orcid{0000-0002-2954-4648}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{vb358@cam.ac.uk}

\author{Martin Kleppmann}
\orcid{0000-0001-7252-6958}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{mk428@cam.ac.uk}

\author{Dominic P.\ Mulligan}
\orcid{0000-0003-4643-3541}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{dpm36@cam.ac.uk}

\author{Alastair R.\ Beresford}
\orcid{0000-0003-0818-6535}
\affiliation{
  \position{Senior Lecturer}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{arb33@cam.ac.uk}

\begin{abstract}
Data replication is used in distributed systems to maintain up-to-date copies of shared data across multiple computers in a network.
However, despite decades of research, algorithms for achieving consistency in replicated systems are still poorly understood.
Indeed, many published algorithms have later been shown to be incorrect, even some that were accompanied by supposed mechanised proofs of correctness.
In this work, we focus on the correctness of Conflict-free Replicated Data Types (CRDTs), a class of algorithm that provides strong eventual consistency guarantees for replicated data.
We develop a modular and reusable framework in the Isabelle/HOL interactive proof assistant for verifying the correctness of CRDT algorithms.
We avoid correctness issues that have dogged previous mechanised proofs in this area by including a network model in our formalisation, and proving that our theorems hold in all possible network behaviours.
Our axiomatic network model is a standard abstraction that accurately reflects the behaviour of real-world computer networks.
Moreover, we identify an abstract convergence theorem, a property of order relations, which provides a formal definition of strong eventual consistency.
We then obtain the first machine-checked correctness theorems for three concrete CRDTs: the Replicated Growable Array, the Observed-Remove Set, and an Increment-Decrement Counter.
We find that our framework is highly reusable, developing proofs of correctness for the latter two CRDTs in a few hours and with relatively little CRDT-specific code.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003033.10003039.10003041.10003042</concept_id>
<concept_desc>Networks~Protocol testing and verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010520.10010521.10010537.10010540</concept_id>
<concept_desc>Computer systems organization~Peer-to-peer architectures</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003033.10003039.10003041.10003043</concept_id>
<concept_desc>Networks~Formal specifications</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10010172</concept_id>
<concept_desc>Theory of computation~Distributed algorithms</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10010124.10010138.10010142</concept_id>
<concept_desc>Theory of computation~Program verification</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011074.10011099.10011692</concept_id>
<concept_desc>Software and its engineering~Formal software verification</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Networks~Protocol testing and verification}
\ccsdesc[500]{Computer systems organization~Peer-to-peer architectures}
\ccsdesc[300]{Networks~Formal specifications}
\ccsdesc[300]{Theory of computation~Distributed algorithms}
\ccsdesc[300]{Theory of computation~Program verification}
\ccsdesc[300]{Software and its engineering~Formal software verification}

\keywords{strong eventual consistency, verification, distributed systems, replication, convergence, CRDTs, automated theorem proving}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sect.introduction}

A data replication algorithm is executed by a set of computers---or \emph{nodes}---in a distributed system, and ensures that all nodes eventually obtain an identical copy of some shared state.
Whilst vital for overall systems correctness, implementing a replication algorithm is a challenging task, as any such algorithm must operate across computer networks that may arbitrarily delay, drop, or reorder messages, experience temporary partitions of the nodes, or even suffer outright node failure.
Reflecting the importance of this task, a number of replication algorithms exist, with different algorithms exploring the inherent trade-offs between the strength of data consistency guarantees, and operational characteristics such as scalability and performance.
Accordingly, replication algorithms can be divided into classes---\emph{strong consistency}, \emph{eventual consistency}, and \emph{strong eventual consistency}---based on the consistency guarantees that they provide.

Strong consistency can be understood as \emph{linearisability}, \emph{serialisability}, or a combination of the two (one-copy serialisability).
Informally, the goal of strong consistency is to make a system behave like a single sequentially executing node, even when it is replicated and concurrent.
Most systems implement strong consistency by designating a single node as the \emph{leader}, which decides on a total order of operations and prevents concurrent access from causing conflicts.
Many relational databases, such as PostgreSQL, use this model.

However, strong consistency may be unwarranted or unnecessary depending on the application: it may impose an unacceptable performance degradation on the system, or it may simply be unfeasible to implement, especially in large distributed systems.
Relying on a single leader or central server limits the use and deployment of these systems: the server may become a bottleneck that limits scalability, and it makes the system vulnerable to disruption by network outages, denial-of-service attacks, censorship, and server failures.
Clients must constantly communicate with the leader in order to perform operations; if a node cannot reach the leader due to a network fault, its execution is stalled.
This fact makes strong consistency unsuitable for mobile devices, such as laptops and smartphones, that have intermittent network connectivity and must work offline.
It also rules out approaches that bypass the central server by using a local network for replication.

By contrast, decentralised or peer-to-peer architectures with weaker consistency models are able to provide better performance, fault-tolerance, and scalability characteristics.
One widely-implemented model is \emph{eventual consistency}, which guarantees that if no new updates are made to the shared state, all nodes will eventually have the same data \cite{Bailis:2013jc,Burckhardt:2014hy,Terry:1994fp,Vogels:2009ca}.
Since this model allows conflicting updates to be made concurrently, it requires a mechanism for resolving such conflicts.
For example, version control systems such as Git or Mercurial require the user to resolve merge conflicts manually; and some ``NoSQL'' distributed database systems such as Cassandra adopt a \emph{last-writer-wins} policy, under which one update is chosen as the winner, and concurrent updates are discarded \cite{KingsburyCassandra}.
Eventual consistency offers weak guarantees: it does not constrain the system behaviour when updates never cease, or the values that read operations may return prior to convergence.

\emph{Strong eventual consistency} (SEC) is a model that strikes a compromise between strong and eventual consistency~\cite{Shapiro:2011un}.
Informally, it guarantees that whenever two nodes have received the same set of updates---possibly in a different order---their view of the shared state is identical, and any conflicting updates are merged automatically.
Large-scale deployments of SEC algorithms include datacentre-based applications using Riak \cite{Brown:2014hs}, and collaborative editing applications such as Google Docs \cite{DayRichter:2010tt}.

Unlike strong consistency models, it is possible to implement SEC in decentralised settings without any central server or leader, and it allows local execution at each node to proceed without waiting for communication with other nodes.
However, algorithms for achieving decentralised SEC are currently poorly understood: several such algorithms, published in peer-reviewed venues, were subsequently shown to violate their supposed guarantees \cite{Imine:2003ks,Imine:2006kn,Oster:2005vi}.
As we show in Section~\ref{sect.relatedwork}, informal reasoning has repeatedly produced plausible-looking but incorrect algorithms, and there have even been examples of mechanised formal proofs of SEC algorithm correctness later being shown to be flawed.
These mechanised proofs failed because, in formalising the algorithm, they made false assumptions about the execution environment.

In this work we use the Isabelle/HOL proof assistant~\cite{DBLP:conf/tphol/WenzelPN08} to create a framework for reliably reasoning about the correctness of a particular class of decentralised replication algorithms.
We do this by formalising not only the replication algorithms, but also the network in which they execute, allowing us to prove that the algorithm's assumptions hold in all possible network behaviours.
We model the network using the axioms of \emph{asynchronous unreliable causal broadcast}, a well-understood abstraction that is commonly implemented by network protocols, and which can run on almost any computer network, including large-scale networks that delay, reorder, or drop messages, and in which nodes may fail.

We then use this framework to produce machine-checked proofs of correctness for three Conflict-Free Replicated Data Types (CRDTs), a class of replication algorithms that ensure strong eventual consistency \cite{Shapiro:2011wy,Shapiro:2011un}.
These algorithms are suitable for use on mobile devices, which are not always connected to the Internet, but which may have a local connection (e.g. via Bluetooth) to other nodes carrying copies of the shared state.
We have used these algorithms to build a collaborative text editing application, and we plan to encapsulate them in a library that will allow developers to easily build applications that require data synchronisation, such as collaboratively editable spreadsheets, shared calendars, address books, and note-taking tools.

Our contributions in this paper are as follows:
\begin{itemize}
\item
We establish a framework for proving the strong eventual consistency (SEC) property of replication algorithms.
Our approach is ``foundational'' in the sense that we start with a general-purpose model of asynchronous unreliable causal broadcast networks---a communication abstraction that is compatible with virtually all network technologies today---and build up composable layers towards a full proof of correctness for a particular algorithm.
To our knowledge, this is the first machine-checked verification of SEC algorithms that explicitly models the network and reasons about all possible network behaviours.
The framework is modular and reusable, making it easy to formulate proofs for new algorithms.
\item
We provide the first mechanised proofs of correctness for the Replicated Growable Array (RGA), the operation-based Observed-Remove Set, and the operation-based counter CRDT.
RGA is an especially subtle algorithm: \citet{Attiya:2016kh} wrote, ``the reason why RGA actually works has been a bit of a mystery'', making its formal verification of interest, whilst the ORSet is supported as a primitive by the Lasp language~\cite{DBLP:conf/ppdp/MeiklejohnR15} for synchronisation-free programming, with an implemention also exported by the Akka framework~\cite{akka}.
These proofs demonstrate that our framework is highly reusable: we were able to quickly develop proofs of convergence for the set and counter CRDTs with little CRDT-specific code, using a fixed proof pattern that applies to all of our CRDTs.
\item
As part of our proof framework, we identify an abstract convergence theorem, a property of order relations, from which we can deduce correctness theorems for concrete SEC algorithms.
Intuitively, this theorem can be viewed as the ``essence'' of why strong eventual consistency algorithms converge.
The convergence theorems for our three concrete CRDTs are obtained as direct corollaries of this theorem.
\end{itemize}

Anonymised Isabelle theory files have been submitted as supplementary material accompanying this paper, and will eventually be made publicly available.

\input{proof-strategy}
\input{isabelle}
\input{convergence}
\input{network}
\input{rga}
\input{simple-crdts}
\input{relwork}

\section{Discussion}
\label{sect.discussion}

The convergence proofs for all of our CRDT implementations follow the same structure.
First we define the type of local state at each node, and the types of operations that may be invoked to modify the state.
When one node invokes an operation, it is broadcast to other nodes using our network model, implemented as a specialisation of the $\isa{network}{\isacharunderscore}\isa{with}{\isacharunderscore}(\isa{constrained}{\isacharunderscore})\isa{ops}$ locale.
An interpretation function function is called whenever a message containing an operation is delivered to a node, and it transforms that node's local state to incorporate the operation.
To demonstrate convergence, we must show that all operations commute with themselves and with each other, subject to certain assumptions.
Next, we must prove that those assumptions are always satisfied by any concurrent operations in the network.
Finally, a CRDT must demonstrate that applying an operation never fails, provided that the operation was constructed according to the definition of the algorithm.

When these proof obligations have been met, we are able to conclude that the algorithm satisfies our abstract specification $\isa{strong-eventual-consistency}$, from which we obtain convergence and progress theorems for the replicated datatype.
The abstract specification is independent of any particular network model or replication algorithm, and we assert that it constitutes a general but precise definition of strong eventual consistency.
As this recurring pattern demonstrates, we have not only isolated reusable lemmas and models of networks, but also a proof strategy that algorithm designers can use to obtain a convergence theorem for their operation-based CRDT.

By line count, over half (around 1000 lines) of our development---the network model, convergence proof, and so on---is independent from any particular CRDT and is reusable in future proofs.
In particular, we use: around 620 lines for our network model, around 380 lines for the abstract convergence proof, 775 lines for the RGA proof, around 270 lines for the ORSet proof, and around 55 lines for the Counter proof.
Additional shared code consists of around 170 lines of source.
We note here that full definitions and proofs of correctness for our three CRDT implementations are pleasingly short: all three are shown to be convergent in less than 800 lines of Isabelle source using the proof strategy described above. 

\section{Conclusion}
\label{sect.conclusion}

In this paper we adopted a ``foundational'' approach to proving the correctness of a class of SEC algorithms: Conflict-free Replicated Datatypes (CRDTs).
In our work, we made no axiomatic assumptions related to any individual algorithm; instead, we constructed a formal, realistic model of a computer network that may delay, drop, or reorder messages sent between computers---a model well known within the distributed systems community, with defensible axioms.
In addition, we isolated a formal specification of SEC, and showed that any algorithm that meets the preconditions of this specification must converge.
Our network model, the SEC specification, and a library of lemmas form a framework with which one can prove convergence for concrete CRDT implementations.

As a case study in applying our framework, we formalised three operation-based CRDTs---the Replicated Growable Array, the Observed-Remove Set, and an increment-decrement Counter.
For each algorithm we proved that its assumptions are satisfied in all possible network behaviours, and that it satisfies the preconditions of our abstract SEC specification, obtaining a guarantee that each of our three CRDT implementations converge.
Moreover, these convergence theorems were obtained using only a thin layer of CRDT-specific code, using a fixed pattern of proof in all three cases.
Since informal reasoning about convergent replication algorithms has been shown to difficult and error-prone, as exemplified by various failed proofs (Section~\ref{sect.related.verification}) and the ``a bit of a mystery'' RGA \cite{Attiya:2016kh}, we believe that their formal verification is particularly important.

Our work has been motivated by the desire to support a wider range of strong eventual consistency algorithms in distributed systems.
Operational Transformation algorithms based on the $\mathit{TP}_1$ property alone are widely used in systems such as Google Docs, but these algorithms require clients to communicate all changes via a single central server.
On the other hand, state-based CRDTs are used in systems such as Riak.
Both of these approaches are limiting.
In the case of Operational Transformation, the requirement for a central server increases the risk of faults, and prevents direct collaboration between devices via local wireless network connections.
In the case of state-based CRDTs, efficient algorithms to support complex data structures such as ordered lists are yet to be found.
Consequently, our approach provides the groundwork for a new generation of applications that use truly distributed strong eventual consistency algorithms, including robust, collaborative applications working on complex data structures in a peer-to-peer setting, something which is likely to become increasingly important in a world where mobile devices are becoming increasingly prevalent.

Although we have focussed on operation-based algorithms in this work, we speculate that our framework is also amenable to formalising Operational Transformation algorithms and state-based CRDTs.
We also speculate that our framework could be used to demonstrate the equivalence of classes of strong eventual consistency algorithms.
We leave this to future work.

%% contents of acknowledgement section are automatically suppressed when the 'anonymous' documentclass option is set
\begin{acks}
    %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and \grantnum[<url>]{<sponsorID>}{<number>}
    %% should be used to acknowledge financial support and will be used by metadata extraction tools.
    The authors wish to acknowledge the support of the~\grantsponsor{GS501100000266}{EPSRC}{http://dx.doi.org/10.13039/501100000266} ``REMS: Rigorous Engineering for Mainstream Systems'' programme grant (\grantnum{GS501100000266}{EP/K008528}),
    the~\grantsponsor{GS501100000266}{EPSRC}{http://dx.doi.org/10.13039/501100000266} ``Interdisciplinary Centre for Finding, Understanding and Countering Crime in the Cloud'' grant (\grantnum{GS501100000266}{EP/M020320}),
    and \grantsponsor{GS100000003}{The Boeing Company}{http://dx.doi.org/10.13039/100000003}.
    We thank Peter Sewell and Alan Mycroft for constructive comments on an earlier version of this paper.
\end{acks}

\pagebreak

\bibliography{references}{}
\end{document}
