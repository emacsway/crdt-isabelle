\documentclass[acmlarge,review,anonymous]{acmart}\settopmatter{printfolios=true}
%\documentclass[acmlarge]{acmart}\settopmatter{}

\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}
\usepackage[english]{babel}
\usepackage{setspace}

\usepackage{paralist} % For inline enumeration
\usepackage{tikz} % For diagrams
\usetikzlibrary{arrows}

\usepackage{isabelle,isabellesym}
\isabellestyle{it}

\newif\ifextended
\extendedfalse

\hyphenation{App-Jet}

%% PACMPL journal information will be supplied by publisher for camera-ready submission
\acmJournal{PACMPL}
\acmVolume{--}
\acmNumber{--}
\acmArticle{0}
\acmYear{2017}
\acmMonth{4}
\acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}
\setcopyright{none}

\begin{document}
\title{Verifying Strong Eventual Consistency in Distributed Systems}

%% Each author should be introduced by \author, followed by \authornote (optional),
%% \orcid (optional), \affiliation, and \email.
%% An author may have multiple affiliations and/or emails; repeat the appropriate command.
%% Many elements are not rendered, but should be provided for metadata extraction tools.
\author{Victor B.\ F.\ Gomes}
%\orcid{nnnn-nnnn-nnnn-nnnn}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{vb358@cam.ac.uk}

\author{Martin Kleppmann}
\orcid{0000-0001-7252-6958}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{mk428@cam.ac.uk}

\author{Dominic P.\ Mulligan}
%\orcid{nnnn-nnnn-nnnn-nnnn}
\affiliation{
  \position{Research Associate}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{dpm36@cam.ac.uk}

\author{Alastair R.\ Beresford}
\orcid{0000-0003-0818-6535}
\affiliation{
  \position{Senior Lecturer}
  \department{Computer Laboratory}
  \institution{University of Cambridge}
  \streetaddress{15 JJ Thomson Avenue}
  \city{Cambridge}
  \postcode{CB3 0FD}
  \country{UK}
}
\email{arb33@cam.ac.uk}

\begin{abstract}
Data replication is used in distributed systems to maintain an up-to-date copy of a data structure across multiple computers in a network, with a variety of algorithms in existence which explore the trade-off between varying levels of data consistency versus operational constraints and system performance.
However, despite decades of research, algorithms for achieving replication in distributed systems are still poorly understood.
Indeed, many published algorithms have later been shown to be incorrect, even those accompanied by supposed mechanised proofs of correctness.

In this work, we focus on the correctness of Conflict-free Replicated Data Types (CRDTs), a class of algorithm that provides Strong Eventual Consistency guarantees for replicated data.
We provide a modular and reusable framework in the Isabelle/HOL interactive theorem prover for verifying the correctness of CRDT implementations.
We sidestep correctness issues that have dogged previous mechanised proofs in this area by axiomatically modelling a large class of networks---the asynchronous causal networks---using five uncontroversial axioms and incrementally building up in composable layers, obtaining a machine-checked assurance that our theorems hold in all possible network behaviours.
We identify an abstract convergence theorem, a property of order relations, with which we obtain correctness theorems for three concrete implementations---the Replicated Growable Array, the Observed-Removed Set, and a increment-decrement counter---as corollaries with a thin-layer of CRDT-specific code, validating our claim to have created a framework for CRDT verification.
\end{abstract}

%\begin{abstract}
%Data replication is used in distributed systems to maintain an up-to-date copy of a data structure across multiple computers, with a variety of data replication algorithms in existence which explore the trade-off between varying levels of data consistency across computers versus operational constraints and system performance.
%In this paper we focus on Conflict-free Replicated Data Types (CRDTs), a class of algorithm which provide Strong Eventual Consistency (SEC).
%These algorithms are worthy of study not only because they are widely used today, but also because previous peer-reviewed SEC algorithms have later turned out to be incorrect, including those which claimed to possess a mechanised proof of correctness.
%Such past failures occurred because the axioms used in proofs were subsequently shown to contain subtle errors.
%The core difficulty in designing SEC algorithms arises from the fact that computer networks may delay, drop and reorder messages sent between computers.
%We therefore construct a realistic, formal model of how a computer network enables communication between machines in a distributed system using just five uncontroversial axioms.
%We implement our framework using the interactive theorem prover Isabelle/HOL, and use it to prove the correctness of SEC algorithms across all possible combinations of message delays, re-orderings and deletions.
%In particular, we provide the first mechanised proofs of convergence for counter, set and ordered-list CRDTs.
%\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003033.10003039.10003041.10003042</concept_id>
<concept_desc>Networks~Protocol testing and verification</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010520.10010521.10010537.10010540</concept_id>
<concept_desc>Computer systems organization~Peer-to-peer architectures</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003033.10003039.10003041.10003043</concept_id>
<concept_desc>Networks~Formal specifications</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10003809.10010172</concept_id>
<concept_desc>Theory of computation~Distributed algorithms</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10003752.10010124.10010138.10010142</concept_id>
<concept_desc>Theory of computation~Program verification</concept_desc>
<concept_significance>300</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011074.10011099.10011692</concept_id>
<concept_desc>Software and its engineering~Formal software verification</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Networks~Protocol testing and verification}
\ccsdesc[500]{Computer systems organization~Peer-to-peer architectures}
\ccsdesc[300]{Networks~Formal specifications}
\ccsdesc[300]{Theory of computation~Distributed algorithms}
\ccsdesc[300]{Theory of computation~Program verification}
\ccsdesc[300]{Software and its engineering~Formal software verification}

\keywords{strong eventual consistency, verification, distributed systems, replication, convergence, CRDTs, automated theorem proving}

\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sect.introduction}

It is almost a clich{\' e} to say that programming distributed systems is hard. Even the most basic
needs of applications---such as \emph{replication}, that is, maintaining a consistent copy of some
data on several nodes---turn out to be difficult to reliably achieve in the face of unreliable
networks and node failures. In this context, a node can be any computer connected to a network, such
as a server in a datacenter, a laptop, a smartphone, or a self-driving car.

Two instances of the replication problem are
\begin{inparaenum}
\item \emph{collaborative editing}, where the data in question is typically a document (text,
    spreadsheet, graphics, CAD, etc.), and several users need to work on it;
\item \emph{data synchronisation}---for example of calendars, address books, note-taking tools,
    to-do lists, and password managers---which is used when a user owns several devices and wants
    the data accessible on each device.
\end{inparaenum}
In both instances, the system must either enforce an exclusive lock for one node and prevent others
from modifying the data concurrently, or deal with the conflicts that ensue when edits are made
concurrently on different nodes.

Enforcing an exclusive lock implies making the data unavailable for writes when a node is offline,
i.e., when it cannot check whether another node already has the lock. Such unavailability is not
acceptable in many applications, so the latter route of accepting and handling conflicts is widely
used: most calendar, address book, and note-taking apps on smartphones, and popular collaborative
editing applications such as Google Docs/Sheets and Microsoft Office Online, choose to allow
conflicts and have mechanisms for resolving them.

However, despite decades of work in both industry and academia, algorithms for achieving replication
with conflict resolution in distributed systems are still poorly understood. As we document in
Section~\ref{sect.relatedwork}, many published algorithms have been shown to be broken, corrupting
the data they are supposed to replicate. Those that are correct tend to be very subtle and easy to
get wrong.

In this work we advance the state of the art of distributed programming by establishing a framework
for formally verifying the correctness of algorithms for achieving consistency in replication,
conflict resolution, and data synchronisation. We demonstrate, for the first time, machine-checked
proofs of correctness of several replicated data structures. Our framework provides general-purpose
tools for such correctness proofs, allowing other algorithms to be verified easily in future.

%%%%%

Most deployed systems today address replication problems by relying on a central server that is
trusted to hold the authoritative copy of the data. The use of a central server introduces a number of limitations:
\begin{itemize}
\item It limits offline usage: for example, a user cannot synchronise changes between their
    smartphone and laptop via a local wireless connection, but must instead connect both devices to
    the internet. It also rules out a group of users collaborating on a local network disconnected
    from the server, for example in a remote location without reliable internet connectivity.
\item Since the central server holds the authoritative copy of the data, all participants must be
    willing to trust it to a high degree. If the server were compromised by attackers, or subverted
    by a malicious insider, it could tamper with the data or grant access to unauthorised parties.
\item Finally, a central server is a single point of failure that is susceptible to distributed
    denial-of-service (DDoS) attacks, blocking, and censorship. For important services that require
    high availability, the risk of being knocked offline by a DDoS attack might be unacceptable. In
    sensitive situations, such as communication among journalists and dissidents under a repressive
    regime, centralisation of communication is also problematic.
\end{itemize}

Decentralised peer-to-peer systems therefore look attractive in scenarios where reliance on a
central server is impractical or undesirable. Unfortunately, we currently have a poor understanding
of algorithms that enable collaborative editing and data synchronisation in peer-to-peer networks.
In Section~\ref{sect.relatedwork} we highlight several algorithms for peer-to-peer collaboration,
published in peer-reviewed venues, that claimed to work correctly but were subsequently shown to violate
their supposed guarantees. Informal reasoning in this domain has repeatedly produced algorithms that
look plausible, but actually turn out to be flawed.

In this work, we contribute to a better understanding of algorithms for peer-to-peer collaboration
by establishing techniques for formally verifying their correctness. We use Isabelle/HOL, a generic
proof assistant tool \cite{DBLP:conf/tphol/WenzelPN08}, to create formal specifications of an
asynchronous network and distributed algorithms executing in such a system. We then use this
framework to produce machine-checked proof of correctness of three different Conflict-Free Replicated Data Types (CRDT) as introduced by
\citet{Shapiro:2011wy,Shapiro:2011un}. We prove in particular the correctness of an algorithm for
peer-to-peer collaboration---the Replicated Growable Array (RGA) of \citet{Roh:2011dw}.
The algorithm is subtle---\citet{Attiya:2016kh} wrote, ``the reason why RGA actually works has been
a bit of a mystery''---which makes formal verification particularly important.

% TODO say more about our contributions. Can recycle some of the following text, but probably needs
% adapting, as the explanation of CRDTs and OT has been moved to the background section...
%
% To date there has been little formal verification of the correctness of CRDTs, and the
% history of broken OT algorithms highlights the inadequacy of informal reasoning in this domain. In
% this work we contribute to the formal basis of collaborative editing algorithms by using the
% interactive proof assistant Isabelle to develop machine-checked proofs of the
% correctness for CRDTs.
%
% By including a model of the network in our proof, we rule out a larger set of potential errors in
% the algorithm that may result from the interaction of operation properties with assumptions about
% the network. Moreover, our network model and convergence theorems are independent of any particular
% CRDT, so they can be reused for correctness proofs of any other replicated datatype that is based on
% operation commutativity, encompassing a wide range of CRDTs~\cite{Baquero:2014ed}.
%
% Besides presenting the first machine-checked proof of the RGA algorithm, our main contribution in
% this paper is to establish a modular toolkit of proof techniques and building blocks for
% machine-checked correctness proofs of operation-based CRDTs. Our proofs are broken down into modules
% with well-defined properties, allowing modules to be reused for proofs of new datatypes in future.
% By making formal verification easier, we hope to provide a strong foundation for the development of

% the next generation of algorithms for collaborative editing.

% TODO put this in section on high-level proof strategy, and just have a forward reference here?
%Our proof is structured in four modules:
%\begin{inparaenum}
%    \item a general convergence theorem that applies in any system where concurrent operations are
%        commutative;
%    \item a formal model of a network protocol providing reliable, causally-ordered broadcast;
%    \item an implementation of the RGA algorithm, and a proof that well-formed, concurrent insertion
%        and deletion operations commute; and
%    \item a proof that when the RGA algorithm is executed in our network model, all possible
%        executions are well-formed, and thus converge.
%\end{inparaenum}


\input{background}
\input{relwork}
\input{isabelle}
\input{convergence}
\input{network}
\input{rga}
\input{simple-crdts}

\section{Conclusion}
\label{sect.conclusion}

In this paper we introduced a new approach for proving the correctness of SEC algorithms: instead of defining axioms related to the basic properties of any individual algorithm, we instead build up from a formal, realistic model of a computer network which may delay, drop or reorder messages sent between computers.
We then complemented this model with an abstract specification of SEC.
We took this approach both to ease the burden of constructing proofs of new SEC algorithms, but also to address the difficulties with previous approaches where peer-reviewed proofs, including mechanised proofs, have later been shown to be incorrect.

We used our framework to show that three op-based CRDT algorithms do indeed provide the SEC property under all possible valid executions of our network model.
Our second and third proofs took only a few hours to write and under 100 lines of additional code, demonstrating that our framework is readily reusable.

All of our convergence proofs for our CRDT implementations follow a familiar recipe.
First local states, or a concrete implementation of the replicated type is defined along with a type of messages corresponding to the operations supported by the CRDT.
Together, these are coupled with an interpretation function which `decodes' messages and lifts them into a transformer of local states.
This transformer is used to define a CRDT-specific locale, a specialisation of the $\isa{network}{\isacharunderscore}\isa{with}{\isacharunderscore}(\isa{constrained}{\isacharunderscore})\isa{ops}$ locale, which may also provide restrictions on valid network behaviours in order to ensure convergence.
Next, all operations are shown to commute with themselves, and with each other, with preconditions on commutation being eventually dischargeable as a side-effect of the restrictions on network behaviours mentioned above.
Coupling our abstract convergence theorem with a CRDT-specific technical lemma showing that the concurrent delivered messages of a prefix of a local history of a node commute, it is easy to prove convergence.
In fact, the same single line of Isabelle proof is used to obtain the convergence theorem as a corollary, in all of our three concrete CRDT implementations.

As this recipe described above demonstrates, in this work we have not only isolated a series of reusable lemmas and models of networks, but also identified a fixed proof strategy that developers of new operation-based CRDTs can use to obtain a convergence theorem for their replicated type.
This idea is made precise with the $\isa{strong}{\isacharunderscore}\isa{eventual}{\isacharunderscore}\isa{consistency}$ local theory, which provides sufficient conditions in order to obtain a convergence theorem for a replicated type.

Our work was motivated by the desire to support a wider range of SEC algorithms in distributed systems.
OT algorithms which support the $\mathit{TP}_1$ alone are already widely used in systems such as Google Docs, however these require all clients communicate changes via a single central server.
Similarly, state-based CRDTs are used in systems such as Riak. Both of these approaches are limiting -- in the case of OT, the requirement for a central server prevents offline editing and direct collaboration via local WiFi; and in the case of state-based CRDTs, algorithms to support complex data structures such as ordered lists are yet to be found and in any case are likely impractical if small changes are regularly made to lists containing many items.
Consequently, our approach provides the groundwork for a new generation of applications which use truly distributed SEC alogrithms, including robust, collaborative applications working on complex data structures in a peer-to-peer setting, something which is likely to become increasingly important in a world where mobile devices are becoming ever more prevalent.

We speculate that our framework is also amenable to the inclusion of SEC algorithms based on OT as well as state-based CRDTs, and not limited to operation-based algorithms, which we have focussed on in this work.
Further, we also speculate that our framework could be used to demonstrate the equivalence of classes of SEC algorithms.
We leave this to future work.

%% contents of acknowledgement section are automatically suppressed when the 'anonymous' documentclass option is set
\begin{acks}
    %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and \grantnum[<url>]{<sponsorID>}{<number>}
    %% should be used to acknowledge financial support and will be used by metadata extraction tools.
    This research was supported by grants from
    \grantsponsor{GS100000003}{The Boeing Company}{http://dx.doi.org/10.13039/100000003} and
    \grantsponsor{GS501100000266}{EPSRC}{http://dx.doi.org/10.13039/501100000266} and
    \grantsponsor{EP/K008528}{EPSRC}{http://dx.doi.org/10.13039/501100000266}

    %TODO: REMS, Colleagues who have provided feedback.
\end{acks}

\bibliography{references}{}
%\input{appendix}

\end{document}
